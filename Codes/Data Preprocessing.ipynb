{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This is for generating Weather Data contraining\n",
    "    1. External Air Temperature\n",
    "    2. Global Horizontal Irradiance (GHI)\n",
    "For running the dwelling heating simulation model\n",
    "\n",
    "The source datafile is downloaded from ShinyWeatherData, which is a free service for downloading weather data."
   ],
   "id": "f996bb1687cc45aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T11:15:29.408287Z",
     "start_time": "2025-08-05T11:15:29.107419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# --- path to the raw file you downloaded from ShinyWeatherData -------------\n",
    "FILE = r\"E:\\Python projects\\RC model\\Weather Data\\file14cff3fc3c1_lat=51.5_lng=-0.25_period=20180101-20231231.csv\"          # ← change if your filename differs\n",
    "OUT  = r\"E:\\Python projects\\RC model\\Weather Data\\Weather_NW9_18_23.csv\"              # optional: where to save the result\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "df = pd.read_csv(FILE, skiprows=11, usecols=['datetime','t2m','ssrd'],index_col='datetime')\n",
    "df.index = pd.to_datetime(df.index, format='%Y-%m-%d %H:%M:%S')\n",
    "df.rename(columns={'t2m': \"External_Air_Temperature\", 'ssrd': \"GHI\"}, inplace=True)\n",
    "df_30 = df.resample(\"30min\").mean().interpolate(method=\"linear\")\n",
    "print(df_30.head(50))\n",
    "\n",
    "df_30.to_csv(OUT, index=True, header=True,index_label='Timestamp')"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     External_Air_Temperature   GHI\n",
      "datetime                                           \n",
      "2018-01-01 00:00:00                      6.90   0.0\n",
      "2018-01-01 00:30:00                      6.60   0.0\n",
      "2018-01-01 01:00:00                      6.30   0.0\n",
      "2018-01-01 01:30:00                      6.10   0.0\n",
      "2018-01-01 02:00:00                      5.90   0.0\n",
      "2018-01-01 02:30:00                      5.80   0.0\n",
      "2018-01-01 03:00:00                      5.70   0.0\n",
      "2018-01-01 03:30:00                      5.55   0.0\n",
      "2018-01-01 04:00:00                      5.40   0.0\n",
      "2018-01-01 04:30:00                      5.40   0.0\n",
      "2018-01-01 05:00:00                      5.40   0.0\n",
      "2018-01-01 05:30:00                      5.45   0.0\n",
      "2018-01-01 06:00:00                      5.50   0.0\n",
      "2018-01-01 06:30:00                      5.40   0.0\n",
      "2018-01-01 07:00:00                      5.30   0.0\n",
      "2018-01-01 07:30:00                      5.25   0.0\n",
      "2018-01-01 08:00:00                      5.20   0.0\n",
      "2018-01-01 08:30:00                      5.25   6.5\n",
      "2018-01-01 09:00:00                      5.30  13.0\n",
      "2018-01-01 09:30:00                      5.60  31.5\n",
      "2018-01-01 10:00:00                      5.90  50.0\n",
      "2018-01-01 10:30:00                      6.10  66.0\n",
      "2018-01-01 11:00:00                      6.30  82.0\n",
      "2018-01-01 11:30:00                      6.45  86.0\n",
      "2018-01-01 12:00:00                      6.60  90.0\n",
      "2018-01-01 12:30:00                      6.70  88.0\n",
      "2018-01-01 13:00:00                      6.80  86.0\n",
      "2018-01-01 13:30:00                      6.85  78.5\n",
      "2018-01-01 14:00:00                      6.90  71.0\n",
      "2018-01-01 14:30:00                      6.85  62.0\n",
      "2018-01-01 15:00:00                      6.80  53.0\n",
      "2018-01-01 15:30:00                      6.65  38.5\n",
      "2018-01-01 16:00:00                      6.50  24.0\n",
      "2018-01-01 16:30:00                      6.30  12.0\n",
      "2018-01-01 17:00:00                      6.10   0.0\n",
      "2018-01-01 17:30:00                      6.15   0.0\n",
      "2018-01-01 18:00:00                      6.20   0.0\n",
      "2018-01-01 18:30:00                      6.40   0.0\n",
      "2018-01-01 19:00:00                      6.60   0.0\n",
      "2018-01-01 19:30:00                      6.75   0.0\n",
      "2018-01-01 20:00:00                      6.90   0.0\n",
      "2018-01-01 20:30:00                      7.00   0.0\n",
      "2018-01-01 21:00:00                      7.10   0.0\n",
      "2018-01-01 21:30:00                      7.05   0.0\n",
      "2018-01-01 22:00:00                      7.00   0.0\n",
      "2018-01-01 22:30:00                      6.75   0.0\n",
      "2018-01-01 23:00:00                      6.50   0.0\n",
      "2018-01-01 23:30:00                      6.30   0.0\n",
      "2018-01-02 00:00:00                      6.10   0.0\n",
      "2018-01-02 00:30:00                      5.85   0.0\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This following part is for analysing and visualizing the metadata of dwellings that are selected to construct the LVN model.\n",
   "id": "add5030dd30eb333"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T07:52:42.895932Z",
     "start_time": "2026-01-12T07:52:42.534455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# --- path to the files ----------------------------------------------\n",
    "FILE_META = r\"E:\\GitHubProjects\\LV network\\Codes\\Data\\EoH Dwellings Metadata.xlsx\"   \n",
    "# ← change if your filename differs\n",
    "FILE_PARAMS = r\"E:\\GitHubProjects\\LV network\\Codes\\Data\\1R1C1P1S_filtered_filtered.csv\"\n",
    "# ---------------------------------------------------------------------------\n",
    "df_meta = pd.read_excel(FILE_META, sheet_name=r'Sheet1', index_col='Property_ID')\n",
    "df_params = pd.read_csv(FILE_PARAMS, index_col='dataset')\n",
    "\n",
    "df_params.index = df_params.index.str[:7]\n",
    "print(df_params.head())"
   ],
   "id": "78538e12f0fb6e9e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            model winter_season          train_start            train_end  \\\n",
      "dataset                                                                     \n",
      "EOH0003  1C1R1P1S     2021-2022  2021-12-03 00:00:00  2022-01-30 23:30:00   \n",
      "EOH0014  1C1R1P1S     2021-2022  2021-12-23 00:00:00  2022-02-19 23:30:00   \n",
      "EOH0018  1C1R1P1S     2021-2022  2021-12-04 00:00:00  2022-02-17 23:30:00   \n",
      "EOH0021  1C1R1P1S     2021-2022  2021-12-02 00:00:00  2022-02-22 23:30:00   \n",
      "EOH0025  1C1R1P1S     2021-2022  2021-12-16 00:00:00  2022-02-27 23:30:00   \n",
      "\n",
      "                   val_start              val_end  \\\n",
      "dataset                                             \n",
      "EOH0003  2021-12-14 00:00:00  2022-02-08 23:30:00   \n",
      "EOH0014  2021-12-25 00:00:00  2022-02-28 23:30:00   \n",
      "EOH0018  2021-12-07 00:00:00  2022-02-06 23:30:00   \n",
      "EOH0021  2021-12-20 00:00:00  2022-02-18 23:30:00   \n",
      "EOH0025  2022-01-12 00:00:00  2022-02-15 23:30:00   \n",
      "\n",
      "                                                train_days  \\\n",
      "dataset                                                      \n",
      "EOH0003  2021-12-03,2021-12-07,2021-12-18,2021-12-20,20...   \n",
      "EOH0014  2021-12-23,2021-12-24,2021-12-29,2022-01-01,20...   \n",
      "EOH0018  2021-12-04,2021-12-05,2021-12-10,2021-12-26,20...   \n",
      "EOH0021  2021-12-02,2021-12-08,2021-12-13,2022-01-06,20...   \n",
      "EOH0025  2021-12-16,2021-12-26,2022-01-15,2022-01-17,20...   \n",
      "\n",
      "                                                 test_days  rmse_train  \\\n",
      "dataset                                                                  \n",
      "EOH0003  2021-12-14,2021-12-17,2021-12-24,2022-01-09,20...    0.504571   \n",
      "EOH0014  2021-12-25,2022-01-17,2022-01-20,2022-02-07,20...    0.709358   \n",
      "EOH0018  2021-12-07,2021-12-21,2022-01-16,2022-01-27,20...    0.702985   \n",
      "EOH0021  2021-12-20,2021-12-26,2022-01-25,2022-02-15,20...    0.361006   \n",
      "EOH0025  2022-01-12,2022-01-22,2022-02-01,2022-02-07,20...    0.345746   \n",
      "\n",
      "         rmse_val  rmse_average  train_day_count  test_day_count        R1  \\\n",
      "dataset                                                                      \n",
      "EOH0003  0.509575      0.507073               10               5  0.007548   \n",
      "EOH0014  0.935808      0.822583               10               5  0.006439   \n",
      "EOH0018  0.893721      0.798353               10               5  0.005212   \n",
      "EOH0021  0.491844      0.426425               10               5  0.004268   \n",
      "EOH0025  0.295474      0.320610               10               5  0.017066   \n",
      "\n",
      "                   C1          g  \n",
      "dataset                           \n",
      "EOH0003  4.091954e+07  13.439900  \n",
      "EOH0014  1.818650e+07   0.249881  \n",
      "EOH0018  2.267737e+07   2.288106  \n",
      "EOH0021  9.130042e+07   0.000001  \n",
      "EOH0025  3.422080e+07   0.000001  \n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T06:06:59.443770Z",
     "start_time": "2026-01-13T06:06:59.430625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_meta_filtered = df_meta[df_meta.index.isin(df_params.index)]\n",
    "print(len(df_meta_filtered))\n",
    "print(len(df_meta))\n",
    "print(len(df_params))"
   ],
   "id": "53969ca2bd64d777",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n",
      "283\n",
      "508\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T06:10:04.457Z",
     "start_time": "2026-01-13T06:10:04.449066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_meta_joint = df_meta.join(df_params, how='inner')\n",
    "print(len(df_meta_joint))"
   ],
   "id": "51222957f9a87827",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T06:16:19.116691Z",
     "start_time": "2026-01-13T06:16:19.103942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_meta_joint = df_meta_joint[df_meta_joint['House_Env']=='Urban']\n",
    "print(len(df_meta_joint))\n"
   ],
   "id": "1c0e3ff8ed9a9833",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T07:19:46.630731Z",
     "start_time": "2026-01-13T07:19:46.611484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_meta_joint['No_occupants'] = df_meta_joint['No_Adults'] + df_meta_joint['No_Child']\n",
    "print(df_meta_joint['No_occupants'].value_counts())"
   ],
   "id": "d336e5c811ccf86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No_occupants\n",
      "2    54\n",
      "3    32\n",
      "4    32\n",
      "1    22\n",
      "5     7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T06:16:28.455348Z",
     "start_time": "2026-01-13T06:16:28.432474Z"
    }
   },
   "cell_type": "code",
   "source": "df_meta_joint.to_csv(r\"E:\\GitHubProjects\\LV network\\Codes\\Data\\EoH_Dwellings_Metadata_filtered.csv\", index=True, header=True,index_label='Property_ID')",
   "id": "592e89cde58262b2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This following part is for converting the NEcase weather data to a 30-min time resolution file containing only temperature and solar radiation data.",
   "id": "97117167d9ad7f76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T06:34:37.602576Z",
     "start_time": "2026-01-20T06:34:34.339498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "in_path = r\"E:\\GitHubProjects\\LV network\\Input data\\NEcase_20_21.csv\"                      # change if needed\n",
    "out_path = r\"E:\\GitHubProjects\\LV network\\Input data\\NEcase_20_21_t2m_ssrd_30min.csv\"      # output file\n",
    "\n",
    "# 1) Read (skip metadata lines starting with '#')\n",
    "df = pd.read_csv(in_path, comment=\"#\")\n",
    "\n",
    "# 2) Pick timestamp column and keep only what you need\n",
    "ts_col = \"datetime\" if \"datetime\" in df.columns else \"datetime_lst\"\n",
    "df = df[[ts_col, \"t2m\", \"ssrd\"]].rename(columns={ts_col: \"timestamp\"})\n",
    "\n",
    "# 3) Parse timestamp + ensure numeric\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
    "df[\"t2m\"] = pd.to_numeric(df[\"t2m\"], errors=\"coerce\")\n",
    "df[\"ssrd\"] = pd.to_numeric(df[\"ssrd\"], errors=\"coerce\")\n",
    "\n",
    "df = df.dropna(subset=[\"timestamp\"]).set_index(\"timestamp\").sort_index()\n",
    "\n",
    "# 4) Upsample to 30-min grid\n",
    "df_30 = df.resample(\"30min\").asfreq()\n",
    "\n",
    "# 5) Fill rules:\n",
    "#    - t2m: interpolate in time\n",
    "#    - ssrd: duplicate (carry forward)\n",
    "df_30[\"t2m\"] = df_30[\"t2m\"].interpolate(method=\"time\")\n",
    "df_30[\"ssrd\"] = df_30[\"ssrd\"].ffill()\n",
    "\n",
    "# 6) Write out\n",
    "df_30.reset_index().to_csv(out_path, index=False)\n",
    "print(f\"Wrote: {out_path}\")\n"
   ],
   "id": "eb2b3c7ea23b6916",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: E:\\GitHubProjects\\LV network\\Input data\\NEcase_20_21_t2m_ssrd_30min.csv\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T06:55:32.897903Z",
     "start_time": "2026-01-20T06:55:32.868676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(r\"E:\\GitHubProjects\\LV network\\Input data\\Newcastle_Urban_Case_meta.csv\")\n",
    "df['No_occupants'] = df['No_Adults'] + df['No_Child']\n",
    "df.to_csv(r\"E:\\GitHubProjects\\LV network\\Input data\\Newcastle_Urban_Case_meta_updated.csv\", index=False)"
   ],
   "id": "f37ad81dd0122e9e",
   "outputs": [],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
